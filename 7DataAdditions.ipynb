{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcb6605",
   "metadata": {},
   "source": [
    "## Bestimmung des dominanten Runway-Concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a72262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datei gespeichert: runway_concept_dominant_HALBHOUR.csv\n",
      "Zeilen: 47,316 | Zeitraum: 2023-01-01 05:50:00 – 2025-09-12 23:20:00\n",
      "Intervalle ohne Flüge: 12,021\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ================================\n",
    "# 1) Pfade & Zeitraum\n",
    "# ================================\n",
    "P_ARR = Path(\"zhaw_export_arrivals.csv\")\n",
    "P_DEP = Path(\"zhaw_export_departures.csv\")\n",
    "OUT_DOMINANT = Path(\"runway_concept_dominant_HALBHOUR.csv\")\n",
    "\n",
    "TIME_START = pd.Timestamp(\"2023-01-01 05:50\")\n",
    "TIME_STOP  = pd.Timestamp(\"2025-09-12 23:20\")\n",
    "\n",
    "# ================================\n",
    "# 2) Helper-Funktionen\n",
    "# ================================\n",
    "def read_semicolon_csv(p: Path):\n",
    "    df = pd.read_csv(p, sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "    if df.shape[1] == 1:\n",
    "        df = pd.read_csv(p, sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "def parse_time_col(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "def get_interval_start(t: pd.Timestamp) -> pd.Timestamp:\n",
    "    \"\"\"xx:20–xx:49 → :20, xx:50–xx:59 → :50, xx:00–xx:19 → vorherige Stunde :50.\"\"\"\n",
    "    if pd.isna(t):\n",
    "        return pd.NaT\n",
    "    m = t.minute\n",
    "    if 20 <= m < 50:\n",
    "        return t.replace(minute=20, second=0, microsecond=0)\n",
    "    elif m >= 50:\n",
    "        return t.replace(minute=50, second=0, microsecond=0)\n",
    "    else:\n",
    "        return (t - pd.Timedelta(hours=1)).replace(minute=50, second=0, microsecond=0)\n",
    "\n",
    "def prep_side(df: pd.DataFrame, time_col: str, label: str) -> pd.DataFrame:\n",
    "    \"\"\"pro (registration, interval) 1 Zeile; runway_concept bereinigt.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[time_col] = parse_time_col(df[time_col])\n",
    "    df = df[(df[time_col] >= TIME_START) & (df[time_col] <= TIME_STOP)]\n",
    "    df[\"interval_start\"] = df[time_col].apply(get_interval_start)\n",
    "    df[\"interval_end\"]   = df[\"interval_start\"] + pd.Timedelta(minutes=30)\n",
    "\n",
    "    if \"aircraft_registration\" not in df.columns:\n",
    "        df[\"aircraft_registration\"] = df.get(\"flight_identifier\", np.nan)\n",
    "\n",
    "    if \"runway_concept\" not in df.columns:\n",
    "        raise ValueError(f\"In den {label}-Daten fehlt 'runway_concept'.\")\n",
    "\n",
    "    df[\"runway_concept\"] = df[\"runway_concept\"].astype(str).str.strip().str.upper()\n",
    "    df.loc[df[\"runway_concept\"] == \"\", \"runway_concept\"] = np.nan\n",
    "\n",
    "    # Codeshares/Mehrfachzeilen raus: pro Flugzeug & Intervall nur 1x\n",
    "    df = df.drop_duplicates(subset=[\"aircraft_registration\", \"interval_start\"])\n",
    "    return df\n",
    "\n",
    "# ================================\n",
    "# 3) Einlesen & Bereinigen\n",
    "# ================================\n",
    "arr = read_semicolon_csv(P_ARR)\n",
    "dep = read_semicolon_csv(P_DEP)\n",
    "\n",
    "req_arr = \"actual_landing_time_utc\"\n",
    "req_dep = \"actual_take_off_time_utc\"\n",
    "if req_arr not in arr.columns:\n",
    "    raise ValueError(f\"In den Arrivals fehlt '{req_arr}'.\")\n",
    "if req_dep not in dep.columns:\n",
    "    raise ValueError(f\"In den Departures fehlt '{req_dep}'.\")\n",
    "\n",
    "arr_u = prep_side(arr, req_arr, \"ARR\")\n",
    "dep_u = prep_side(dep, req_dep, \"DEP\")\n",
    "\n",
    "# ================================\n",
    "# 4) Konzept je Flugzeug+Intervall bestimmen\n",
    "# ================================\n",
    "all_flights = pd.concat([arr_u, dep_u], ignore_index=True)\n",
    "\n",
    "# Falls ein Flugzeug im selben Intervall mehrere Konzepte hat → meistgenutztes wählen\n",
    "concept_per_flight_int = (all_flights\n",
    "    .groupby([\"aircraft_registration\", \"interval_start\", \"runway_concept\"], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={\"size\": \"n\"})\n",
    ")\n",
    "idxmax = concept_per_flight_int.groupby([\"aircraft_registration\", \"interval_start\"])[\"n\"].idxmax()\n",
    "flight_concepts = concept_per_flight_int.loc[idxmax, [\"aircraft_registration\", \"interval_start\", \"runway_concept\"]].copy()\n",
    "flight_concepts[\"interval_end\"] = flight_concepts[\"interval_start\"] + pd.Timedelta(minutes=30)\n",
    "\n",
    "# ================================\n",
    "# 5) Dominantes Konzept + Gesamtzahl der betrachteten Flüge je Intervall\n",
    "#    - dominant_runway_concept: Konzept mit meisten Flügen im Intervall\n",
    "#    - dominant_runway_count:   *Gesamtzahl* der Flüge, die in die Dominanzwahl eingeflossen sind\n",
    "# ================================\n",
    "# Counts pro Intervall & Konzept\n",
    "concept_counts = (\n",
    "    flight_concepts.groupby([\"interval_start\", \"interval_end\", \"runway_concept\"], as_index=False)\n",
    "    .agg(n_flights=(\"aircraft_registration\", \"nunique\"))\n",
    ")\n",
    "\n",
    "# Dominantes Konzept wählen\n",
    "idx_dom = concept_counts.groupby([\"interval_start\", \"interval_end\"])[\"n_flights\"].idxmax()\n",
    "dominant = concept_counts.loc[idx_dom, [\"interval_start\", \"interval_end\", \"runway_concept\"]].copy()\n",
    "dominant = dominant.rename(columns={\"runway_concept\": \"dominant_runway_concept\"})\n",
    "\n",
    "# *** NEU: Gesamtzahl der berücksichtigten Flüge je Intervall ***\n",
    "total_considered = (\n",
    "    flight_concepts.groupby([\"interval_start\", \"interval_end\"], as_index=False)\n",
    "    .agg(dominant_runway_count=(\"aircraft_registration\", \"nunique\"))\n",
    ")\n",
    "\n",
    "dominant = dominant.merge(total_considered, on=[\"interval_start\", \"interval_end\"], how=\"right\")\n",
    "\n",
    "# ================================\n",
    "# 6) Lückenloses Intervall-Grid & Merge (auch Nachtruhe-Intervalle)\n",
    "# ================================\n",
    "grid = pd.DataFrame({\"interval_start\": pd.date_range(TIME_START, TIME_STOP, freq=\"30min\")})\n",
    "grid[\"interval_end\"] = grid[\"interval_start\"] + pd.Timedelta(minutes=30)\n",
    "\n",
    "out = grid.merge(dominant, on=[\"interval_start\", \"interval_end\"], how=\"left\")\n",
    "out[\"dominant_runway_concept\"] = out[\"dominant_runway_concept\"].fillna(\"\")\n",
    "out[\"dominant_runway_count\"]   = out[\"dominant_runway_count\"].fillna(0).astype(int)\n",
    "\n",
    "# ================================\n",
    "# 7) Speichern & Diagnose\n",
    "# ================================\n",
    "out = out.sort_values(\"interval_start\").reset_index(drop=True)\n",
    "out.to_csv(OUT_DOMINANT, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ Datei gespeichert: {OUT_DOMINANT}\")\n",
    "print(f\"Zeilen: {len(out):,} | Zeitraum: {out['interval_start'].min()} – {out['interval_start'].max()}\")\n",
    "print(f\"Intervalle ohne Flüge: {(out['dominant_runway_count']==0).sum():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adf61e",
   "metadata": {},
   "source": [
    "## Kategorisierung METAR Visibility Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08dc2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datei erstellt: visibility_categories_HALBHOUR.csv\n",
      "                        time    vis_m vis_cat\n",
      "0  2023-01-01 05:50:00+00:00  10000.0       H\n",
      "1  2023-01-01 06:20:00+00:00  10000.0       H\n",
      "2  2023-01-01 06:50:00+00:00  10000.0       H\n",
      "3  2023-01-01 07:20:00+00:00  10000.0       H\n",
      "4  2023-01-01 07:50:00+00:00  10000.0       H\n",
      "ℹ️ 20 Zeilen ohne ermittelte Sichtweite.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Dateien\n",
    "# =========================\n",
    "FILE_METAR  = \"metar_official_HALBHOUR_MATCHED.csv\"\n",
    "OUTPUT_FILE = \"visibility_categories_HALBHOUR.csv\"\n",
    "\n",
    "df_metar = pd.read_csv(FILE_METAR)\n",
    "\n",
    "# =========================\n",
    "# Zeitspalte / Join-Key erkennen\n",
    "# =========================\n",
    "def guess_time_key(df: pd.DataFrame):\n",
    "    candidates = [\n",
    "        \"time\", \"timestamp\", \"timestamp_utc\", \"datetime\", \"datetime_utc\",\n",
    "        \"interval\", \"interval_start\", \"interval_start_utc\", \"ts\", \"dt\"\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    # Fallback: Index\n",
    "    df[\"_rowidx_\"] = np.arange(len(df))\n",
    "    return \"_rowidx_\"\n",
    "\n",
    "key = guess_time_key(df_metar)\n",
    "\n",
    "# =========================\n",
    "# Sichtweite extrahieren\n",
    "# =========================\n",
    "def parse_vis_from_text(s: str):\n",
    "    \"\"\"Extrahiert Zahlen aus Text wie '8000 metres' oder '10 km'.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return None\n",
    "    s_low = s.lower()\n",
    "\n",
    "    km_match = re.search(r'(\\d{1,3})\\s*km', s_low)\n",
    "    if km_match:\n",
    "        return int(km_match.group(1)) * 1000\n",
    "\n",
    "    m_match = re.search(r'(\\d{2,5})\\s*m(?:etre|eter|)\\b', s_low)\n",
    "    if m_match:\n",
    "        return int(m_match.group(1))\n",
    "\n",
    "    num_match = re.search(r'\\b(\\d{2,5})\\b', s_low)\n",
    "    if num_match:\n",
    "        return int(num_match.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_visibility(row):\n",
    "    \"\"\"Versucht, Sichtweite zu bestimmen – erst vis, dann code.\"\"\"\n",
    "    vis_val = None\n",
    "\n",
    "    # 1) aus 'vis'\n",
    "    if \"vis\" in row and pd.notna(row[\"vis\"]):\n",
    "        vis_val = parse_vis_from_text(str(row[\"vis\"]))\n",
    "\n",
    "    # 2) falls leer → aus 'code'\n",
    "    if (vis_val is None) and (\"code\" in row) and pd.notna(row[\"code\"]):\n",
    "        code = str(row[\"code\"]).upper()\n",
    "\n",
    "        if \"CAVOK\" in code:\n",
    "            return 10001  # >10 km\n",
    "\n",
    "        if re.search(r'\\b9999\\b', code):\n",
    "            return 10000\n",
    "\n",
    "        m = re.search(r'\\b(\\d{4})\\b', code)\n",
    "        if m:\n",
    "            vis_val = int(m.group(1))\n",
    "\n",
    "        sm = re.search(r'P?(\\d+)\\s*SM', code)\n",
    "        if (vis_val is None) and sm:\n",
    "            vis_val = int(sm.group(1)) * 1609\n",
    "\n",
    "    return vis_val\n",
    "\n",
    "\n",
    "# Sichtweite berechnen\n",
    "df_metar[\"vis_m\"] = df_metar.apply(extract_visibility, axis=1)\n",
    "df_metar[\"vis_m\"] = pd.to_numeric(df_metar[\"vis_m\"], errors=\"coerce\").clip(lower=0)\n",
    "\n",
    "# =========================\n",
    "# Kategorien bilden (A–H)\n",
    "# =========================\n",
    "def vis_category(v):\n",
    "    if pd.isna(v):\n",
    "        return np.nan\n",
    "    v = int(v)\n",
    "    if 0 <= v <= 200:\n",
    "        return \"A\"\n",
    "    elif v <= 500:\n",
    "        return \"B\"\n",
    "    elif v <= 1000:\n",
    "        return \"C\"\n",
    "    elif v <= 2000:\n",
    "        return \"D\"\n",
    "    elif v <= 4000:\n",
    "        return \"E\"\n",
    "    elif v <= 7000:\n",
    "        return \"F\"\n",
    "    elif v <= 9998:\n",
    "        return \"G\"\n",
    "    else:\n",
    "        return \"H\"\n",
    "\n",
    "df_metar[\"vis_cat\"] = df_metar[\"vis_m\"].apply(vis_category)\n",
    "\n",
    "# =========================\n",
    "# Relevante Spalten auswählen & speichern\n",
    "# =========================\n",
    "out = df_metar[[key, \"vis_m\", \"vis_cat\"]].copy()\n",
    "out.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"✅ Datei erstellt:\", OUTPUT_FILE)\n",
    "print(out.head())\n",
    "print(f\"ℹ️ {out['vis_m'].isna().sum()} Zeilen ohne ermittelte Sichtweite.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9ccd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zeit-Features gespeichert in: time_features_HALBHOUR.csv\n",
      "         Time of Prediction  Hour sin  Hour cos  Minute sin  Minute cos  \\\n",
      "0 2023-01-01 05:50:00+00:00  0.982963   0.62941    0.066987        0.75   \n",
      "1 2023-01-01 06:20:00+00:00  1.000000   0.50000    0.933013        0.25   \n",
      "2 2023-01-01 06:50:00+00:00  1.000000   0.50000    0.066987        0.75   \n",
      "3 2023-01-01 07:20:00+00:00  0.982963   0.37059    0.933013        0.25   \n",
      "4 2023-01-01 07:50:00+00:00  0.982963   0.37059    0.066987        0.75   \n",
      "\n",
      "   Day of week sin  Day of week cos  Month sin  Month cos  Year sin  Year cos  \n",
      "0         0.109084         0.811745       0.75   0.933013  0.996057  0.562667  \n",
      "1         0.109084         0.811745       0.75   0.933013  0.996057  0.562667  \n",
      "2         0.109084         0.811745       0.75   0.933013  0.996057  0.562667  \n",
      "3         0.109084         0.811745       0.75   0.933013  0.996057  0.562667  \n",
      "4         0.109084         0.811745       0.75   0.933013  0.996057  0.562667  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# INPUT & OUTPUT\n",
    "# =========================\n",
    "# Nimm hier eine Datei, die dein komplettes HALBHOUR-Zeitgitter enthält.\n",
    "# Falls du nur die Zeitachse willst, kannst du z.B. metar_official_HALBHOUR_MATCHED.csv nehmen.\n",
    "INPUT_FILE  = \"metar_official_HALBHOUR_MATCHED.csv\"   # ggf. anpassen\n",
    "OUTPUT_FILE = \"time_features_HALBHOUR.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# =========================\n",
    "# Zeitspalte erkennen & aufbereiten\n",
    "# =========================\n",
    "def guess_time_key(df: pd.DataFrame):\n",
    "    candidates = [\n",
    "        \"Time of Prediction\",   # bevorzugt, wenn schon vorhanden\n",
    "        \"time\", \"timestamp\", \"timestamp_utc\", \"datetime\", \"datetime_utc\",\n",
    "        \"interval\", \"interval_start\", \"interval_start_utc\", \"ts\", \"dt\"\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise RuntimeError(\"Keine Zeitspalte gefunden. Bitte eine der üblichen Spaltennamen verwenden.\")\n",
    "\n",
    "time_col = guess_time_key(df)\n",
    "\n",
    "# In datetime konvertieren (ohne harte TZ-Annahme; falls String mit TZ, bleibt sie erhalten)\n",
    "df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "if df[time_col].isna().any():\n",
    "    raise ValueError(\"Mindestens eine Zeitzeile konnte nicht geparst werden. Prüfe das Eingabefile.\")\n",
    "\n",
    "# Für die nachfolgende Logik nennen wir sie wie in deiner Vorlage:\n",
    "df = df.rename(columns={time_col: \"Time of Prediction\"})\n",
    "\n",
    "# =========================\n",
    "# Diskrete Zeitfeatures\n",
    "# =========================\n",
    "final_table = pd.DataFrame()\n",
    "final_table[\"Time of Prediction\"] = df[\"Time of Prediction\"]\n",
    "\n",
    "final_table[\"Hour\"]        = final_table[\"Time of Prediction\"].dt.hour\n",
    "final_table[\"Minute\"]      = final_table[\"Time of Prediction\"].dt.minute\n",
    "final_table[\"Day of week\"] = final_table[\"Time of Prediction\"].dt.weekday  # Mo=0..So=6\n",
    "final_table[\"Month\"]       = final_table[\"Time of Prediction\"].dt.month\n",
    "final_table[\"Year\"]        = final_table[\"Time of Prediction\"].dt.year % 100  # wie Vorlage (0..99)\n",
    "\n",
    "# =========================\n",
    "# Zyklisches Encoding (wie Vorlage, 0..1 skaliert)\n",
    "# =========================\n",
    "def cyclic_enc(df_, feature, max_val):\n",
    "    df_[feature + \" sin\"] = 0.5 * np.sin(2 * np.pi * df_[feature] / max_val) + 0.5\n",
    "    df_[feature + \" cos\"] = 0.5 * np.cos(2 * np.pi * df_[feature] / max_val) + 0.5\n",
    "    return df_\n",
    "\n",
    "def encode_df(df_):\n",
    "    df_ = cyclic_enc(df_, \"Hour\", 24)\n",
    "    df_ = cyclic_enc(df_, \"Minute\", 60)\n",
    "    df_ = cyclic_enc(df_, \"Day of week\", 7)\n",
    "    df_ = cyclic_enc(df_, \"Month\", 12)\n",
    "    df_ = cyclic_enc(df_, \"Year\", 100)\n",
    "    # Originale nach dem Encoding entfernen (Vorlagen-konform)\n",
    "    df_ = df_.drop(columns=[\"Hour\", \"Minute\", \"Day of week\", \"Month\", \"Year\"])\n",
    "    return df_\n",
    "\n",
    "final_table = encode_df(final_table)\n",
    "\n",
    "# =========================\n",
    "# Speichern\n",
    "# =========================\n",
    "final_table.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✅ Zeit-Features gespeichert in: {OUTPUT_FILE}\")\n",
    "print(final_table.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04043686",
   "metadata": {},
   "source": [
    "## Erstellung zyklisch encodierter Zeit-Features aus HALBHOUR-Zeitstempeln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bc560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Windrichtungs-Features gespeichert in: wind_direction_HALBHOUR.csv\n",
      "         Time of Prediction  wind_dir_deg  wind_dir sin  wind_dir cos\n",
      "0 2023-01-01 05:50:00+00:00         220.0      0.178606      0.116978\n",
      "1 2023-01-01 06:20:00+00:00         240.0      0.066987      0.250000\n",
      "2 2023-01-01 06:50:00+00:00         230.0      0.116978      0.178606\n",
      "3 2023-01-01 07:20:00+00:00         240.0      0.066987      0.250000\n",
      "4 2023-01-01 07:50:00+00:00         240.0      0.066987      0.250000\n",
      "ℹ️ 13571 Zeilen ohne feste Richtung (z. B. VRB).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# INPUT & OUTPUT\n",
    "# =========================\n",
    "INPUT_FILE  = \"metar_official_HALBHOUR_MATCHED.csv\"\n",
    "OUTPUT_FILE = \"wind_direction_HALBHOUR.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# =========================\n",
    "# Zeitspalte erkennen & aufbereiten\n",
    "# =========================\n",
    "def guess_time_key(df: pd.DataFrame):\n",
    "    candidates = [\n",
    "        \"Time of Prediction\",   # bevorzugt\n",
    "        \"time\", \"timestamp\", \"timestamp_utc\", \"datetime\", \"datetime_utc\",\n",
    "        \"interval\", \"interval_start\", \"interval_start_utc\", \"ts\", \"dt\"\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise RuntimeError(\"Keine Zeitspalte gefunden. Bitte eine der üblichen Spaltennamen verwenden.\")\n",
    "\n",
    "time_col = guess_time_key(df)\n",
    "df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "if df[time_col].isna().any():\n",
    "    raise ValueError(\"Mindestens eine Zeitzeile konnte nicht geparst werden. Prüfe das Eingabefile.\")\n",
    "\n",
    "\n",
    "df = df.rename(columns={time_col: \"Time of Prediction\"})\n",
    "\n",
    "# =========================\n",
    "# Windrichtung extrahieren\n",
    "# =========================\n",
    "def parse_wind_dir(val, code_text=None):\n",
    "    \"\"\"\n",
    "    Erwartet z. B. '320 degrees'.\n",
    "    Fallbacks:\n",
    "      - 'VRB' → np.nan (keine feste Richtung)\n",
    "      - '000' → 0 Grad\n",
    "      - Aus 'code' (METAR)  dddVVKT  (z.B. '32012KT', 'VRB03KT') erkennen.\n",
    "    \"\"\"\n",
    "    # 1) Primär aus wind_dir\n",
    "    if isinstance(val, str):\n",
    "        s = val.strip().upper()\n",
    "        if \"VRB\" in s:\n",
    "            return np.nan\n",
    "        m = re.search(r'\\b(\\d{1,3})\\s*DEGREE', s)  # '320 DEGREES' / '320 degree'\n",
    "        if m:\n",
    "            deg = int(m.group(1)) % 360\n",
    "            return deg\n",
    "        # reine Zahl?\n",
    "        m2 = re.search(r'\\b(\\d{1,3})\\b', s)\n",
    "        if m2:\n",
    "            return int(m2.group(1)) % 360\n",
    "\n",
    "    # 2) Fallback: aus METAR code (falls übergeben)\n",
    "    if isinstance(code_text, str):\n",
    "        ct = code_text.upper()\n",
    "        # VRBxxKT\n",
    "        if re.search(r'\\bVRB\\d{2,3}KT\\b', ct):\n",
    "            return np.nan\n",
    "        # dddxxKT (ddd = 000..360)\n",
    "        m = re.search(r'\\b(\\d{3})(\\d{2,3})KT\\b', ct)\n",
    "        if m:\n",
    "            deg = int(m.group(1))\n",
    "            if 0 <= deg <= 360:\n",
    "                return (0 if deg == 360 else deg)\n",
    "    return np.nan\n",
    "\n",
    "# Falls 'code' existiert, mit durchreichen für Fallback\n",
    "has_code = \"code\" in df.columns\n",
    "df[\"wind_dir_deg\"] = [\n",
    "    parse_wind_dir(row.get(\"wind_dir\", np.nan), row.get(\"code\", None) if has_code else None)\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Zyklisches Encoding (0..1 skaliert, wie bei dir)\n",
    "# =========================\n",
    "def cyclic_enc_deg(series_deg, period=360):\n",
    "    rad = 2 * np.pi * (series_deg % period) / period\n",
    "    sin_col = 0.5 * np.sin(rad) + 0.5\n",
    "    cos_col = 0.5 * np.cos(rad) + 0.5\n",
    "    # NaNs beibehalten\n",
    "    sin_col[series_deg.isna()] = np.nan\n",
    "    cos_col[series_deg.isna()] = np.nan\n",
    "    return sin_col, cos_col\n",
    "\n",
    "df[\"wind_dir sin\"], df[\"wind_dir cos\"] = cyclic_enc_deg(df[\"wind_dir_deg\"], period=360)\n",
    "\n",
    "# =========================\n",
    "# Speichern (nur Zeit + Features)\n",
    "# =========================\n",
    "out = df[[\"Time of Prediction\", \"wind_dir_deg\", \"wind_dir sin\", \"wind_dir cos\"]].copy()\n",
    "out.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"✅ Windrichtungs-Features gespeichert in: {OUTPUT_FILE}\")\n",
    "print(out.head())\n",
    "print(f\"ℹ️ {out['wind_dir_deg'].isna().sum()} Zeilen ohne feste Richtung (z. B. VRB).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414eb2d8",
   "metadata": {},
   "source": [
    "## Merge der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4858b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ visibility geladen (47316 Zeilen) | dtype: datetime64[ns, UTC] | tz=UTC\n",
      "✅ time geladen (47316 Zeilen) | dtype: datetime64[ns, UTC] | tz=UTC\n",
      "✅ wind geladen (47316 Zeilen) | dtype: datetime64[ns, UTC] | tz=UTC\n",
      "✅ runway geladen (47316 Zeilen) | dtype: datetime64[ns, UTC] | tz=UTC\n",
      "\n",
      "✅ Add-ons erfolgreich zusammengeführt: addons_merged_HALBHOUR.csv\n",
      "Spalten: ['Time of Prediction', 'Hour sin', 'Hour cos', 'Minute sin', 'Minute cos', 'Day of week sin', 'Day of week cos', 'Month sin', 'Month cos', 'Year sin', 'Year cos', 'vis_m', 'vis_cat', 'wind_dir_deg', 'wind_dir sin', 'wind_dir cos', 'interval_end', 'dominant_runway_concept', 'dominant_runway_count']\n",
      "         Time of Prediction  Hour sin  Hour cos  Minute sin  Minute cos  \\\n",
      "0 2023-01-01 05:50:00+00:00  0.982963   0.62941    0.066987        0.75   \n",
      "1 2023-01-01 06:20:00+00:00  1.000000   0.50000    0.933013        0.25   \n",
      "2 2023-01-01 06:50:00+00:00  1.000000   0.50000    0.066987        0.75   \n",
      "3 2023-01-01 07:20:00+00:00  0.982963   0.37059    0.933013        0.25   \n",
      "4 2023-01-01 07:50:00+00:00  0.982963   0.37059    0.066987        0.75   \n",
      "\n",
      "   Day of week sin  Day of week cos  Month sin  Month cos  Year sin  Year cos  \\\n",
      "0         0.109084         0.811745       0.75   0.933013  0.996057  0.562667   \n",
      "1         0.109084         0.811745       0.75   0.933013  0.996057  0.562667   \n",
      "2         0.109084         0.811745       0.75   0.933013  0.996057  0.562667   \n",
      "3         0.109084         0.811745       0.75   0.933013  0.996057  0.562667   \n",
      "4         0.109084         0.811745       0.75   0.933013  0.996057  0.562667   \n",
      "\n",
      "     vis_m vis_cat  wind_dir_deg  wind_dir sin  wind_dir cos  \\\n",
      "0  10000.0       H         220.0      0.178606      0.116978   \n",
      "1  10000.0       H         240.0      0.066987      0.250000   \n",
      "2  10000.0       H         230.0      0.116978      0.178606   \n",
      "3  10000.0       H         240.0      0.066987      0.250000   \n",
      "4  10000.0       H         240.0      0.066987      0.250000   \n",
      "\n",
      "          interval_end dominant_runway_concept  dominant_runway_count  \n",
      "0  2023-01-01 06:20:00              EVENING_C1                      5  \n",
      "1  2023-01-01 06:50:00              EVENING_C1                      4  \n",
      "2  2023-01-01 07:20:00               NORTHWEST                     13  \n",
      "3  2023-01-01 07:50:00               NORTHWEST                     19  \n",
      "4  2023-01-01 08:20:00               NORTHWEST                     13  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Dateipfade\n",
    "# =========================\n",
    "FILES = {\n",
    "    \"visibility\": \"visibility_categories_HALBHOUR.csv\",\n",
    "    \"time\": \"time_features_HALBHOUR.csv\",\n",
    "    \"wind\": \"wind_direction_HALBHOUR.csv\",\n",
    "    \"runway\": \"runway_concept_dominant_HALBHOUR.csv\",\n",
    "}\n",
    "OUTPUT_FILE = \"addons_merged_HALBHOUR.csv\"\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def guess_time_key(df: pd.DataFrame):\n",
    "    candidates = [\n",
    "        \"Time of Prediction\",\"time\",\"timestamp\",\"timestamp_utc\",\n",
    "        \"datetime\",\"datetime_utc\",\"interval\",\"interval_start\",\"interval_start_utc\"\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise RuntimeError(\"Keine Zeitspalte erkannt. Bitte manuell prüfen.\")\n",
    "\n",
    "def to_utc(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Sorgt dafür, dass die Zeitspalte tz-aware in UTC ist.\"\"\"\n",
    "    s = pd.to_datetime(series, errors=\"coerce\", utc=False)\n",
    "    # Wenn schon tz-aware -> nach UTC konvertieren\n",
    "    if getattr(s.dtype, \"tz\", None) is not None:\n",
    "        return s.dt.tz_convert(\"UTC\")\n",
    "    # Wenn naiv -> als UTC interpretieren (dein Grid ist in UTC)\n",
    "    return s.dt.tz_localize(\"UTC\")\n",
    "\n",
    "# =========================\n",
    "# Dateien einlesen & harmonisieren\n",
    "# =========================\n",
    "dfs = {}\n",
    "for name, path in FILES.items():\n",
    "    df = pd.read_csv(path)\n",
    "    key = guess_time_key(df)\n",
    "    df[key] = to_utc(df[key])\n",
    "    df = df.rename(columns={key: \"Time of Prediction\"})\n",
    "    # Optional: Duplikate pro Zeitstempel entfernen (falls vorhanden)\n",
    "    if df.duplicated(subset=[\"Time of Prediction\"]).any():\n",
    "        # Nimm die erste Zeile pro Zeitstempel. Alternativ: aggregieren.\n",
    "        df = df.sort_values(\"Time of Prediction\").drop_duplicates(subset=[\"Time of Prediction\"], keep=\"first\")\n",
    "        print(f\"ℹ️ Duplikate in '{name}' entfernt (first wins).\")\n",
    "    dfs[name] = df\n",
    "    tzinfo = getattr(df[\"Time of Prediction\"].dtype, \"tz\", None)\n",
    "    print(f\"✅ {name} geladen ({len(df)} Zeilen) | dtype: {df['Time of Prediction'].dtype} | tz={tzinfo}\")\n",
    "\n",
    "# =========================\n",
    "# Mergen aller Add-ons\n",
    "# =========================\n",
    "merged = dfs[\"time\"].copy()\n",
    "for name in [\"visibility\", \"wind\", \"runway\"]:\n",
    "    before = len(merged)\n",
    "    merged = merged.merge(dfs[name], on=\"Time of Prediction\", how=\"left\")\n",
    "    after = len(merged)\n",
    "    if after != before:\n",
    "        print(f\"⚠️ Hinweis: Merge mit '{name}' hat die Zeilenanzahl verändert ({before} → {after}). \"\n",
    "              f\"Prüfe ggf. Duplikate oder Nicht-Eindeutigkeit der Zeitstempel im Add-on.\")\n",
    "\n",
    "# =========================\n",
    "# Ausgabe\n",
    "# =========================\n",
    "merged.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\n✅ Add-ons erfolgreich zusammengeführt: {OUTPUT_FILE}\")\n",
    "print(f\"Spalten: {list(merged.columns)}\")\n",
    "print(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72c601e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time of Prediction</th>\n",
       "      <th>Hour sin</th>\n",
       "      <th>Hour cos</th>\n",
       "      <th>Minute sin</th>\n",
       "      <th>Minute cos</th>\n",
       "      <th>Day of week sin</th>\n",
       "      <th>Day of week cos</th>\n",
       "      <th>Month sin</th>\n",
       "      <th>Month cos</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>vis_m</th>\n",
       "      <th>vis_cat</th>\n",
       "      <th>wind_dir_deg</th>\n",
       "      <th>wind_dir sin</th>\n",
       "      <th>wind_dir cos</th>\n",
       "      <th>interval_end</th>\n",
       "      <th>dominant_runway_concept</th>\n",
       "      <th>dominant_runway_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 05:50:00+00:00</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.629410</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.811745</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>0.116978</td>\n",
       "      <td>2023-01-01 06:20:00</td>\n",
       "      <td>EVENING_C1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 06:20:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.811745</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2023-01-01 06:50:00</td>\n",
       "      <td>EVENING_C1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 06:50:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.811745</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.116978</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>2023-01-01 07:20:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 07:20:00+00:00</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.370590</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.811745</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2023-01-01 07:50:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 07:50:00+00:00</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.370590</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.811745</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2023-01-01 08:20:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47311</th>\n",
       "      <td>2025-09-12 21:20:00+00:00</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.283058</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-12 21:50:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47312</th>\n",
       "      <td>2025-09-12 21:50:00+00:00</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.283058</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-12 22:20:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47313</th>\n",
       "      <td>2025-09-12 22:20:00+00:00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.283058</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>0.883022</td>\n",
       "      <td>2025-09-12 22:50:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47314</th>\n",
       "      <td>2025-09-12 22:50:00+00:00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.283058</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>H</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.116978</td>\n",
       "      <td>0.821394</td>\n",
       "      <td>2025-09-12 23:20:00</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47315</th>\n",
       "      <td>2025-09-12 23:20:00+00:00</td>\n",
       "      <td>0.370590</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.283058</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-12 23:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47316 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time of Prediction  Hour sin  Hour cos  Minute sin  Minute cos  \\\n",
       "0      2023-01-01 05:50:00+00:00  0.982963  0.629410    0.066987        0.75   \n",
       "1      2023-01-01 06:20:00+00:00  1.000000  0.500000    0.933013        0.25   \n",
       "2      2023-01-01 06:50:00+00:00  1.000000  0.500000    0.066987        0.75   \n",
       "3      2023-01-01 07:20:00+00:00  0.982963  0.370590    0.933013        0.25   \n",
       "4      2023-01-01 07:50:00+00:00  0.982963  0.370590    0.066987        0.75   \n",
       "...                          ...       ...       ...         ...         ...   \n",
       "47311  2025-09-12 21:20:00+00:00  0.146447  0.853553    0.933013        0.25   \n",
       "47312  2025-09-12 21:50:00+00:00  0.146447  0.853553    0.066987        0.75   \n",
       "47313  2025-09-12 22:20:00+00:00  0.250000  0.933013    0.933013        0.25   \n",
       "47314  2025-09-12 22:50:00+00:00  0.250000  0.933013    0.066987        0.75   \n",
       "47315  2025-09-12 23:20:00+00:00  0.370590  0.982963    0.933013        0.25   \n",
       "\n",
       "       Day of week sin  Day of week cos  Month sin  Month cos  Year sin  \\\n",
       "0             0.109084         0.811745       0.75   0.933013  0.996057   \n",
       "1             0.109084         0.811745       0.75   0.933013  0.996057   \n",
       "2             0.109084         0.811745       0.75   0.933013  0.996057   \n",
       "3             0.109084         0.811745       0.75   0.933013  0.996057   \n",
       "4             0.109084         0.811745       0.75   0.933013  0.996057   \n",
       "...                ...              ...        ...        ...       ...   \n",
       "47311         0.283058         0.049516       0.00   0.500000  1.000000   \n",
       "47312         0.283058         0.049516       0.00   0.500000  1.000000   \n",
       "47313         0.283058         0.049516       0.00   0.500000  1.000000   \n",
       "47314         0.283058         0.049516       0.00   0.500000  1.000000   \n",
       "47315         0.283058         0.049516       0.00   0.500000  1.000000   \n",
       "\n",
       "       Year cos    vis_m vis_cat  wind_dir_deg  wind_dir sin  wind_dir cos  \\\n",
       "0      0.562667  10000.0       H         220.0      0.178606      0.116978   \n",
       "1      0.562667  10000.0       H         240.0      0.066987      0.250000   \n",
       "2      0.562667  10000.0       H         230.0      0.116978      0.178606   \n",
       "3      0.562667  10000.0       H         240.0      0.066987      0.250000   \n",
       "4      0.562667  10000.0       H         240.0      0.066987      0.250000   \n",
       "...         ...      ...     ...           ...           ...           ...   \n",
       "47311  0.500000  10000.0       H           NaN           NaN           NaN   \n",
       "47312  0.500000  10000.0       H           NaN           NaN           NaN   \n",
       "47313  0.500000  10000.0       H         320.0      0.178606      0.883022   \n",
       "47314  0.500000  10000.0       H         310.0      0.116978      0.821394   \n",
       "47315  0.500000      NaN     NaN           NaN           NaN           NaN   \n",
       "\n",
       "              interval_end dominant_runway_concept  dominant_runway_count  \n",
       "0      2023-01-01 06:20:00              EVENING_C1                      5  \n",
       "1      2023-01-01 06:50:00              EVENING_C1                      4  \n",
       "2      2023-01-01 07:20:00               NORTHWEST                     13  \n",
       "3      2023-01-01 07:50:00               NORTHWEST                     19  \n",
       "4      2023-01-01 08:20:00               NORTHWEST                     13  \n",
       "...                    ...                     ...                    ...  \n",
       "47311  2025-09-12 21:50:00               NORTHWEST                     24  \n",
       "47312  2025-09-12 22:20:00               NORTHWEST                     24  \n",
       "47313  2025-09-12 22:50:00               NORTHWEST                     18  \n",
       "47314  2025-09-12 23:20:00               NORTHWEST                     10  \n",
       "47315  2025-09-12 23:50:00                     NaN                      0  \n",
       "\n",
       "[47316 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel: Finale Tabelle laden\n",
    "df = pd.read_csv(\"addons_merged_HALBHOUR.csv\")\n",
    "\n",
    "\n",
    "df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
